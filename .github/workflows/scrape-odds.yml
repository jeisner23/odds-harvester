name: Scrape Soccer Odds (7-Day Tiered)

on:
  schedule:
    # Tier 1 (Today + Tomorrow): Every 4 hours - most accurate
    - cron: '0 */4 * * *'
  workflow_dispatch:
    inputs:
      tier:
        description: 'Which tier to run (1=today+tomorrow, 2=days3-4, 3=days5-7, all=everything)'
        required: false
        default: 'all'

# Tier refresh strategy:
# - Tier 1 (Today + Tomorrow): Every 4 hours via cron
# - Tier 2 (Days 3-4): Every 8 hours via separate workflow  
# - Tier 3 (Days 5-7): Once daily via separate workflow
# This workflow handles Tier 1; see scrape-odds-extended.yml for Tiers 2-3

jobs:
  day-0:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.tier == 'all' || github.event.inputs.tier == '1' || github.event.inputs.tier == ''
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install playwright aiohttp fake_useragent tenacity boto3 beautifulsoup4 lxml
          playwright install chromium
          playwright install-deps chromium
      
      - name: Get date
        id: date
        run: echo "DATE=$(date -u +%Y%m%d)" >> $GITHUB_OUTPUT
      
      - name: Scrape Day 0 (Today)
        continue-on-error: true
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python src/main.py scrape_upcoming \
            --sport football \
            --date ${{ steps.date.outputs.DATE }} \
            --markets 1x2,over_under_2_5,btts \
            --headless \
            --file_path data/day0.json \
            --format json \
            --concurrency_tasks 5
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: day-0
          path: data/*.json
          retention-days: 1

  day-1:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.tier == 'all' || github.event.inputs.tier == '1' || github.event.inputs.tier == ''
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install playwright aiohttp fake_useragent tenacity boto3 beautifulsoup4 lxml
          playwright install chromium
          playwright install-deps chromium
      
      - name: Get date
        id: date
        run: echo "DATE=$(date -u -d '+1 day' +%Y%m%d)" >> $GITHUB_OUTPUT
      
      - name: Scrape Day 1 (Tomorrow)
        continue-on-error: true
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python src/main.py scrape_upcoming \
            --sport football \
            --date ${{ steps.date.outputs.DATE }} \
            --markets 1x2,over_under_2_5,btts \
            --headless \
            --file_path data/day1.json \
            --format json \
            --concurrency_tasks 5
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: day-1
          path: data/*.json
          retention-days: 1

  day-2:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.tier == 'all' || github.event.inputs.tier == '1' || github.event.inputs.tier == ''
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install playwright aiohttp fake_useragent tenacity boto3 beautifulsoup4 lxml
          playwright install chromium
          playwright install-deps chromium
      
      - name: Get date
        id: date
        run: echo "DATE=$(date -u -d '+2 days' +%Y%m%d)" >> $GITHUB_OUTPUT
      
      - name: Scrape Day 2
        continue-on-error: true
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python src/main.py scrape_upcoming \
            --sport football \
            --date ${{ steps.date.outputs.DATE }} \
            --markets 1x2,over_under_2_5,btts \
            --headless \
            --file_path data/day2.json \
            --format json \
            --concurrency_tasks 5
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: day-2
          path: data/*.json
          retention-days: 1

  day-3:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.tier == 'all' || github.event.inputs.tier == '2' || github.event.inputs.tier == ''
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install playwright aiohttp fake_useragent tenacity boto3 beautifulsoup4 lxml
          playwright install chromium
          playwright install-deps chromium
      
      - name: Get date
        id: date
        run: echo "DATE=$(date -u -d '+3 days' +%Y%m%d)" >> $GITHUB_OUTPUT
      
      - name: Scrape Day 3
        continue-on-error: true
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python src/main.py scrape_upcoming \
            --sport football \
            --date ${{ steps.date.outputs.DATE }} \
            --markets 1x2,over_under_2_5,btts \
            --headless \
            --file_path data/day3.json \
            --format json \
            --concurrency_tasks 5
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: day-3
          path: data/*.json
          retention-days: 1

  day-4:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.tier == 'all' || github.event.inputs.tier == '2' || github.event.inputs.tier == ''
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install playwright aiohttp fake_useragent tenacity boto3 beautifulsoup4 lxml
          playwright install chromium
          playwright install-deps chromium
      
      - name: Get date
        id: date
        run: echo "DATE=$(date -u -d '+4 days' +%Y%m%d)" >> $GITHUB_OUTPUT
      
      - name: Scrape Day 4
        continue-on-error: true
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python src/main.py scrape_upcoming \
            --sport football \
            --date ${{ steps.date.outputs.DATE }} \
            --markets 1x2,over_under_2_5,btts \
            --headless \
            --file_path data/day4.json \
            --format json \
            --concurrency_tasks 5
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: day-4
          path: data/*.json
          retention-days: 1

  day-5:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.tier == 'all' || github.event.inputs.tier == '3' || github.event.inputs.tier == ''
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install playwright aiohttp fake_useragent tenacity boto3 beautifulsoup4 lxml
          playwright install chromium
          playwright install-deps chromium
      
      - name: Get date
        id: date
        run: echo "DATE=$(date -u -d '+5 days' +%Y%m%d)" >> $GITHUB_OUTPUT
      
      - name: Scrape Day 5
        continue-on-error: true
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python src/main.py scrape_upcoming \
            --sport football \
            --date ${{ steps.date.outputs.DATE }} \
            --markets 1x2,over_under_2_5,btts \
            --headless \
            --file_path data/day5.json \
            --format json \
            --concurrency_tasks 5
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: day-5
          path: data/*.json
          retention-days: 1

  day-6:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.tier == 'all' || github.event.inputs.tier == '3' || github.event.inputs.tier == ''
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install playwright aiohttp fake_useragent tenacity boto3 beautifulsoup4 lxml
          playwright install chromium
          playwright install-deps chromium
      
      - name: Get date
        id: date
        run: echo "DATE=$(date -u -d '+6 days' +%Y%m%d)" >> $GITHUB_OUTPUT
      
      - name: Scrape Day 6
        continue-on-error: true
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python src/main.py scrape_upcoming \
            --sport football \
            --date ${{ steps.date.outputs.DATE }} \
            --markets 1x2,over_under_2_5,btts \
            --headless \
            --file_path data/day6.json \
            --format json \
            --concurrency_tasks 5
      
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: day-6
          path: data/*.json
          retention-days: 1

  merge:
    needs: [day-0, day-1, day-2, day-3, day-4, day-5, day-6]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Merge all odds files
        run: python scripts/merge_odds.py
      
      - name: Upload odds to Gist
        uses: exuanbo/actions-deploy-gist@v1
        with:
          token: ${{ secrets.GIST_TOKEN }}
          gist_id: ${{ secrets.GIST_ID }}
          file_path: data/odds.json
          file_type: text
